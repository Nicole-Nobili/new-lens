{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from tuned_lens.nn.lenses import TunedLens\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from typing import Counter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 13:06:03,991 - __main__ - INFO - Initializing logger...\n"
     ]
    }
   ],
   "source": [
    "from lenses_experiments.utils.logger import get_logger\n",
    "\n",
    "logger = get_logger(name = __name__)\n",
    "logger.info(\"Initializing logger...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-410m-deduped\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-410m-deduped\")\n",
    "tuned_lens = TunedLens.from_model_and_pretrained(model)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenses_experiments.utils.datasets import Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Loader(dataset_name=\"allenai/ai2_arc\", dataset=dataset, tokenizer=tokenizer, device=model.device)\n",
    "val_dataloader = loader.loader_normal\n",
    "wrong_loader = loader.loader_injected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [00:16<04:40, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '1', 'A', '1', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2/18 [00:29<03:49, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '1', 'A', 'A', 'A', 'A', '1', 'A', 'A', 'A', 'A', 'A', 'A', '1', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3/18 [00:43<03:35, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'D', 'A', '1', 'A', '1', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4/18 [00:59<03:27, 14.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', '1', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5/18 [01:10<02:55, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '1', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '\\n', 'A', 'A', 'B']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6/18 [01:20<02:27, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', '1', 'A', 'A', 'A', 'A', 'A', 'A', 'C', '1', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', '1', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7/18 [01:31<02:11, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '\\n', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8/18 [01:44<02:03, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'C', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 9/18 [01:55<01:46, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', '\\n', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '\\n']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 10/18 [02:05<01:30, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '1', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 11/18 [02:18<01:21, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'B', 'C', 'B', '1', '1', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [02:28<01:08, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '\\n', 'A', 'A', 'A', 'A', 'A', 'C', '1', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 13/18 [02:44<01:03, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'D', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '1', '\\n', 'A', 'B', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 14/18 [02:54<00:47, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', '\\n', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([31, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 15/18 [03:04<00:34, 11.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'A', '1', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([31, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 16/18 [03:17<00:23, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 17/18 [03:33<00:13, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', '1', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [03:41<00:00, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top answers given by last lenses index: ['1', 'A', 'A', 'A', 'A', 'B', 'A', 'A', '1', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '\\n', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Top answers given by first lenses index: ['\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n",
      "torch.Size([25, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "n_layers = model.config.num_hidden_layers + 1\n",
    "n_hidden = model.config.hidden_size\n",
    "n_vocab = model.config.vocab_size\n",
    "\n",
    "correct_sum = 0\n",
    "n_batches = len(val_dataloader)\n",
    "\n",
    "features = []\n",
    "\n",
    "for batch in tqdm(val_dataloader):\n",
    "    pr, encoded_prompt, encoded_labels, correct_encoded_labels = batch\n",
    "\n",
    "    n_batch = len(encoded_prompt.input_ids)\n",
    "    encoded_labels = torch.tensor(encoded_labels).squeeze() #batch_size x n_choices\n",
    "    correct_encoded_labels = torch.tensor(correct_encoded_labels).squeeze() #batch_size\n",
    "    correct_encoded_labels = torch.tensor([torch.nonzero(encoded_labels[idx] == correct_encoded_labels[idx]).squeeze().item() for idx in range(correct_encoded_labels.shape[0])])\n",
    "    inputs = encoded_prompt.input_ids\n",
    "    attention_mask = encoded_prompt.attention_mask\n",
    "    last_nonzero_tok_index = attention_mask.sum(dim=1) - 1  #which indexes to take for each prompt: the last token position\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        traj_log_probs = torch.empty(n_batch, n_layers, n_vocab)\n",
    "\n",
    "        #getting logits at last token position\n",
    "        logits_last_token = outputs.logits[torch.arange(n_batch), last_nonzero_tok_index, :].squeeze() #shape: (batchsize, vocab_size)\n",
    "        traj_log_probs[:,-1,:] = logits_last_token.log_softmax(dim=-1) #shape: (batchsize, vocab_size)\n",
    "    \n",
    "\n",
    "        #getting hidden states at last token position\n",
    "        hidden_states_last_token = torch.empty(n_batch, n_layers-1, n_hidden)\n",
    "        hidden_states = outputs.hidden_states #shape: (layers, batchsize, seq_len, hidden_size)\n",
    "        \n",
    "        for layer_index in range(len(hidden_states[:-1])):\n",
    "            for elem_index in range(len(hidden_states[layer_index])):\n",
    "                hidden_states_last_token[elem_index][layer_index] = hidden_states[layer_index][elem_index][last_nonzero_tok_index[elem_index],:]\n",
    "\n",
    "        #getting lens outputs from hidden states last token\n",
    "        for layer_index in range(n_layers-1):\n",
    "            traj_log_probs[:,layer_index,:] = tuned_lens.forward(hidden_states_last_token[:,layer_index,:], layer_index).log_softmax(dim=-1)\n",
    "\n",
    "        print(f\"Top answers given by last lenses index: {[tokenizer.decode(el) for el in traj_log_probs[:,-2].argmax(dim=-1).squeeze().tolist()]}\")\n",
    "        print(f\"Top answers given by first lenses index: {[tokenizer.decode(el) for el in traj_log_probs[:,0].argmax(dim=-1).squeeze().tolist()]}\")\n",
    "        #transform the trajectory into the trajectory for the encoded labels\n",
    "        traj_log_probs_filtered = torch.empty(n_batch, n_layers, len(encoded_labels[0]))\n",
    "\n",
    "        correct_batch = 0\n",
    "        for i in range(n_batch):\n",
    "            traj_log_probs_filtered[i] = traj_log_probs[i,:,encoded_labels[i]]\n",
    "            if(traj_log_probs_filtered[i,-1,correct_encoded_labels[i]].squeeze() == traj_log_probs_filtered[i,-1,:].max().squeeze()):\n",
    "                correct_batch += 1\n",
    "        #print(\"correct answer ratio for this batch: \", correct_batch/n_batch)\n",
    "        correct_sum += correct_batch/n_batch\n",
    "\n",
    "        traj_log_probs_flatten = traj_log_probs_filtered.flatten(start_dim=1)\n",
    "        print(traj_log_probs_flatten.shape)\n",
    "        features.append(traj_log_probs_flatten)\n",
    "\n",
    "        #print(traj_log_probs_filtered.shape)\n",
    "features = torch.cat(features, dim=0)\n",
    "\n",
    "#print(correct_sum/n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
